---
author: "Rishav Ray"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, fig.height = 4)
library(tidyverse)
library(lubridate)
library(scales)
library(modelr)
source("viridis.R")
source("ggprob.R")
```

\renewcommand{\prob}{\mathsf{P}}
\newcommand{\E}{\mathsf{E}}
\newcommand{\Var}{\mathsf{Var}}
\newcommand{\SD}{\mathsf{SD}}
\newcommand{\SE}{\mathsf{SE}}

## Homework Assignment 11

#### Due Friday, April 28, 2022, at 11:59 PM

### Preliminaries

- Directories
    - COURSE/homework/
    - COURSE/homework/hw11/
    - COURSE/data/
    - COURSE/scripts/
- Files
  - COURSE/homework/hw11/hw11.Rmd
  - COURSE/data/boston-marathon-data.csv
  - COURSE/data/dugong.csv
  - COURSE/scripts/viridis.R
  - COURSE/scripts/ggprob.R

### Data

- Some problems use the official Madison weather data, `madison-weather-official-1869-2022.csv`.
- Additional problems use the Boston Marathon data in the file `boston-marathon-data.csv`. This file is a transformed version of the raw data we used in class and has data for all runners who completed the race in 2010 and 2011. The variable `Time` is the sum of the times from the different portions of the race, each of which begins with "K".

### Aims HAHAHAHAHA

- Practice regression

## Problems

  **1.** In a regression problem to estimate $y$ from explanatory variable $x$ from a sample of size $n$, partial summary information is $\bar{x} = 20$ and $\bar{y} = 100$. Regardless of the values of other summary statistics, what is the value the predicted value $\hat{y}$ at a point where $x = 20$? Briefly explain.
  
> Let the line of best-fit of the sample be denoted by y = a + bx, and the correlation coefficient between x and y in the sample be denoted by r. b = r * (sigma of y)/(sigma of x), & a = 100-20 * b. Altogether, y = 100-20 * b + r * (sigma of y)/(sigma of x) * x. For x=20, y  = (sigma of y)/(sigma of x) * r * 20 + 100 - (sigma of y)/(sigma of x) * r * 20. Thus, the predicted value for the sample is y=100 at x=20.




  **2.** In a regression problem to estimate $y$ from explanatory variable $x$ from a sample of size $n$, partial summary information is $\bar{x} = 20$, $s_x = 5$, $\bar{y} = 100$, and $s_y = 15$. Which of the following values are possible values for the predicted value $\hat{y}$ when the explanatory variable has value $x = 30$? Briefly explain.
  
**(a)** 50      
**(b)** 70      
**(c)** 100      
**(d)** 120    
**(e)** 150

> Answer: (b) ? I would be able to provide a more detailed answer if I was made aware of the correlation coefficient between x and y.



Problems 3--6 are based on the data set in the file *dugong.csv* which relates age (in years) and length (in meters) of a sample of 27 dugongs, a type of marine mammal.
  
Credit:  The *dugong.csv* file is from Data8 at UC-Berkeley.


  **3.**

- Read in the *dugong.csv* data set.  
-  Create a scatter plot with `length` on the x-axis and `age` on the y-axis; be sure to add descriptive axis labels (include units of measurement) and a title.  
-  Using `geom_smooth()`, add the least-squares line to your plot.

```{r}
dugong = read_csv("dugong.csv")
ggplot(dugong, aes(x=Length,y=Age)) + geom_point() + geom_smooth(method=lm, se=FALSE) + xlab("Length of Dugong") + ylab("Age of Dugong") + ggtitle("Age vs Length of Dugongs, UC-Berkeley")
```





  **4.** 
- Using the dugong data, calculate the sample means, sample standard deviations, and correlation coefficient of the variables `age` and `length`.
- Using formulas from lecture, calculate the slope and intercept of the least squares regressions line to predict age with length.

```{r}
meanLength = mean(dugong$Length)
meanAge = mean(dugong$Age)
sigmaLength = sd(dugong$Length)
sigmaAge =  sd(dugong$Age)
correlationCoefficient = cor(dugong$Length, dugong$Age)
regressionSlope = round(correlationCoefficient * sigmaAge/sigmaLength,2)
regressionYIntercept = round(meanAge - regressionSlope*meanLength,2)
regressionSlope
regressionYIntercept
print("Regression line: y = 23.77x-44.57")

```

- Use the dugong data and the functions `lm()` and `coef()` to calculate the slope and intercept of the least squares regression line of age against length (use length to predict age).

```{r}
dugong_lm = lm(Age ~ Length, data = dugong)
dugong_lm
print("Regression line: y = 23.77x-44.57")


```

> The two regression lines indeed match.






  **5.**

- Add columns with the predicted values and residuals to the dugong data set. *(You can use* **modelr** *functions or just use `mutate()` and calculate these values directly.)*
- Plot the residuals versus length.
    - Add a horizontal line at $y=0$ and appropriate labels on each axis.

```{r}
dugong_aug = dugong %>% mutate()
dugong_aug$.resid = resid(dugong_lm)
dugong_aug$.pred = fitted(dugong_lm)

ggplot(dugong_aug,aes(x=Length,y=.resid)) + geom_point() + geom_hline(yintercept=0) + xlab("Length of Dugong") + ylab("Residual from Line of Best-Fit") + ggtitle("Residual vs Dugong Length, UC-Berkeley")
```

- Describe what the residual plot suggests about the appropriateness of using simple linear regression to predict age from length of dugongs.

> The residual plot suggests that a linear model is appropriate, because there is no visible pattern where residuals are increasing/decreasing; furthermore, although there are a few obvious outliers, for the majority of the datapoints have an absolute value of residual less than 5(which is not too high). The appropriateness of a simple linear regression can also be backed by the correlation-coefficient of 0.83.







  **6.**

- Print the summary of the fitted regression model

```{r}
print(summary(dugong_lm))

```

- The simple linear regression model for $Y_i$ conditional on the values of $X_i = x_i$ is

$$
\E(Y_i \mid X_i = x_i) = \beta_0 + \beta_1 x_i + \varepsilon_i, \quad \text{for $i = 1, \ldots,n$}
$$

where $\varepsilon_i \sim \text{Normal}(0, \sigma)$
for some parameter $\sigma > 0$.

- The parameter $\sigma$ is the unknown population standard deviation of the typical distance between a point $Y_i$ and its true expected value.

- Use the function `sigma()` on the fitted regression object (what you created with `lm()`) to extract the estimate of $\sigma$. Identify where this numerical value appears in the printed summary you made earlier.

```{r}
sigma(dugong_lm)

```
> This numerical value is appears as the Residual Standard Error in the printed summary.

- The numerical estimate of $\sigma$ here is not quite the standard deviation of the residuals because the denominator is $n-2$, the degrees of freedom in simple linear regression, instead of $n-1$, the degrees of freedom from a single numerical sample.

- Use the column of residuals in the augments data set `dugong` and verify that:
    - the mean of the residuals equals zero (numerically, it might be very close).
    - you arrive at the numerical estimate of $\sigma$ by calculating
    
$$
\sqrt{ \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n-2} }
$$

where the $i$th residual is $y_i - \hat{y}_i$.

```{r}
mean(dugong_aug$.resid)
sqrt(sum(dugong_aug$.resid ^ 2)/25)
```

> Mean is very close to 0. And my calculations for deriving residual standard error matches that of R!





- Problems 7--8 use the cleaned Boston Marathon data in `boston-marathon-data.csv`.


  **7.**

- Read in the Boston marathon data from the file `boston-marathon-data.csv`.

```{r}
bmar = read_csv("boston-marathon-data-2.csv")
```

- Create a scatter plots of `Time` versus `Age` for the female runners in 2010.
    - Add a straight regression line
    - Add a smooth curve
- As there are so many points, you may set `alpha` to a value less than one inside of `geom_point()` to lessen the effects of overplotting.    
    
```{r}
bmarFemales2010  = bmar %>% filter(Year==2010 & Sex=="female")
ggplot(bmar,aes(x=Age,y=Time)) + geom_point(alpha=0.6) + geom_smooth(method=lm) + xlab("Age of Runner") + ylab("Time taken to Complete Marathon") + ggtitle("Time vs Age, 2010 Boston Marathon Females")

```
    
- Make a residual plot of the residuals versus `Age`.
    - Include a horizontal line at $y=0$
    - Include a smooth curve through the residuals

- In addition, make a density plot of the residuals.    
```{r}

bmarFemales2010 = bmarFemales2010 %>% select(Age,Time) 
bmarFemales2010$.resid = resid(lm(Time~Age, data=bmarFemales2010))
ggplot(bmarFemales2010, aes(x=Age, y=.resid)) + geom_point() + geom_smooth() + ggtitle("Residual vs Age, 2010 Boston Marathon Females") + xlab("Age of Runner") + ylab("Residual from Line of Best-Fit") + geom_hline(yintercept=0) 

```







  **8.** Examine the residual plots from the previous problem.
  
- Is there evidence of strong non-linearity?

> Yes. This can even be backed by the correlation-coefficent between age and residual being extremely close to 0.

- Is there evidence that the standard deviation of the residuals varies substantially with changes in age?

> There does not appear to be strong evidence to support this claim, for the most part.


- Is there evidence that the error distribution for individual residuals is not symmetric?

> The error-distribution appears symmetric if you were to only consider runners aged from 20 to 60, but not from 20 to 75.
